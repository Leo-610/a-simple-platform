<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>大数据平台分析与实验报告 - By Leo-610</title>
    <style>
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        body {
            background-color: #f0f2f5;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, 'Noto Sans', sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
            margin: 0;
            padding: 40px 20px;
            color: #333;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
        }

        .card {
            background-color: white;
            border-radius: 12px;
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.07);
            padding: 30px 40px;
            margin-bottom: 30px;
            opacity: 0;
            transform: translateY(30px);
            transition: opacity 0.6s ease-out, transform 0.6s ease-out;
        }
        
        .card.is-visible {
            opacity: 1;
            transform: translateY(0);
        }

        h1, h2, h3, h4 {
            color: #1f2d3d;
            font-weight: 600;
        }

        h1 {
            text-align: center;
            font-size: 32px;
            margin-bottom: 10px;
        }
        
        .subtitle {
            text-align: center;
            color: #8492a6;
            margin-bottom: 40px;
            font-size: 16px;
        }

        h2 {
            font-size: 26px;
            margin-bottom: 25px;
            padding-bottom: 10px;
            border-bottom: 1px solid #e0e6ed;
        }

        h3 {
            font-size: 22px;
            margin-top: 35px;
            margin-bottom: 20px;
            border-left: 4px solid #409eff;
            padding-left: 15px;
        }
        
        h4 {
            font-size: 18px;
            color: #3c4858;
            margin-top: 30px;
            margin-bottom: 15px;
        }

        p, li {
            line-height: 1.8;
            font-size: 16px;
            color: #5a6573;
        }

        ul {
            padding-left: 25px;
        }
        
        li {
            margin-bottom: 12px;
            transition: transform 0.2s ease-in-out;
        }
        
        li:hover {
            transform: translateX(5px);
        }

        #chart-container {
            width: 100%;
            height: 450px;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 15px;
            text-align: left;
        }

        th, td {
            padding: 14px 18px;
            border: 1px solid #dfe6ec;
        }

        th {
            background-color: #f5f7fa;
            font-weight: 600;
        }

        tbody tr:nth-of-type(even) {
            background-color: #fafcff;
        }
        
        blockquote {
            margin: 20px 0;
            padding: 15px 20px;
            border-left: 5px solid #e6a23c;
            background-color: #fdf6ec;
            color: #c08c42;
        }
        
        blockquote strong {
            color: #b88237;
        }

    </style>
    <script src="https://cdn.jsdelivr.net/npm/echarts@5.5.0/dist/echarts.min.js"></script>
</head>
<body>
    <div class="container">
        <h1>大数据平台分析与实验报告</h1>
        <p class="subtitle">Hadoop WordCount 任务可视化 & 集群搭建报告</p>

        <div class="card" id="chart-card">
            <h2>Hadoop WordCount 任务 - 词频分析可视化</h2>
            <div id="chart-container"></div>
        </div>

        <div class="card" id="report-card">
            <h2>大数据平台 (Hadoop) 集群安装与配置实验报告</h2>
            <p style="text-align: center; color: #8492a6; margin-top: -20px; margin-bottom: 30px;">
                <strong>实验者：</strong> 刘一鸣 | <strong>实验日期：</strong> 2025年10月07日 | <strong>指导：</strong> GitHub Copilot
            </p>

            <section>
                <h3>摘要</h3>
                <p>本实验报告详细记录了从零开始，在阿里云ECS（Elastic Compute Service）云服务器上搭建一个小型高可用Hadoop大数据平台的全过程。实验采用一个主节点（Master）和两个从节点（Slave）的经典架构，成功部署了Hadoop 3.3.6版本，并完成了其核心组件HDFS（分布式文件系统）和YARN（资源管理器）的配置。报告不仅涵盖了标准的安装配置流程，还重点记录了在网络配置、SSH免密登录、环境变量设置等环节中遇到的实际问题及其解决方案。最终，通过运行经典的WordCount MapReduce任务，成功验证了集群的可用性和功能的完整性。</p>
            </section>

            <section>
                <h3>1. 实验概述</h3>
                <h4>1.1 背景与目的</h4>
                <p>随着数据量的爆炸式增长，以Hadoop为代表的分布式计算框架已成为大数据处理领域的事实标准。为了深入理解Hadoop的架构原理和运行机制，亲手搭建一个Hadoop集群是至关重要的实践环节。本次实验的核心目的在于：</p>
                <ul>
                    <li>掌握在真实的云环境中规划和部署分布式集群的基本方法。</li>
                    <li>熟悉Linux环境下Hadoop的安装、配置与优化流程。</li>
                    <li>理解Hadoop核心组件（HDFS, YARN, MapReduce）之间的协同工作关系。</li>
                    <li>锻炼和提升在复杂技术实践中分析问题、解决问题的能力。</li>
                </ul>
                <h4>1.2 技术栈与环境</h4>
                <table>
                    <thead>
                        <tr>
                            <th>类别</th>
                            <th>具体信息</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>云计算平台</td>
                            <td>阿里云 ECS</td>
                        </tr>
                        <tr>
                            <td>服务器实例</td>
                            <td>3台 ecs.e-c1m1.large (2核vCPU, 2GiB内存)</td>
                        </tr>
                        <tr>
                            <td>操作系统</td>
                            <td>Ubuntu Server 20.04 LTS 64位</td>
                        </tr>
                        <tr>
                            <td>核心框架</td>
                            <td>Apache Hadoop 3.3.6</td>
                        </tr>
                        <tr>
                            <td>运行环境</td>
                            <td>OpenJDK 1.8.0</td>
                        </tr>
                    </tbody>
                </table>
            </section>
            
            <section>
                <h3>2. 实验环境规划</h3>
                <table>
                    <thead>
                        <tr>
                            <th>角色</th>
                            <th>主机名</th>
                            <th>公网IP (登录用)</th>
                            <th>内网IP (集群通信)</th>
                            <th>部署的核心服务</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>主节点 (Master)</td>
                            <td>hadoop-master</td>
                            <td>112.124.111.13</td>
                            <td>172.29.212.174</td>
                            <td>NameNode, SecondaryNameNode, ResourceManager</td>
                        </tr>
                        <tr>
                            <td>从节点1 (Slave)</td>
                            <td>hadoop-slave1</td>
                            <td>112.124.110.110</td>
                            <td>172.29.212.175</td>
                            <td>DataNode, NodeManager</td>
                        </tr>
                        <tr>
                            <td>从节点2 (Slave)</td>
                            <td>hadoop-slave2</td>
                            <td>47.118.19.190</td>
                            <td>172.29.212.176</td>
                            <td>DataNode, NodeManager</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section>
                <h3>3. 实验详细步骤</h3>
                <h4>3.1 阶段一：服务器准备与网络配置</h4>
                <ul>
                    <li><strong>创建云服务器：</strong>在阿里云平台创建3台配置相同的ECS实例，并配置统一的安全组 sg-hadoop，确保它们位于同一VPC和交换机下，以便内网互通。</li>
                    <li><strong>创建用户：</strong>在所有服务器上创建专用于Hadoop的hadoop用户，并授予sudo权限，以实现权限分离和安全管理。</li>
                    <li><strong>配置网络映射：</strong>为三台服务器分别设置规划好的主机名，并编辑/etc/hosts文件，添加所有成员的内网IP与主机名的映射关系。</li>
                </ul>
                <blockquote>
                    <strong>问题排查与解决：网络孤岛</strong><br>
                    <strong>问题描述：</strong> 初次配置时，发现hadoop-slave2的内网IP与其他两台不在同一网段，导致ping不通。<br>
                    <strong>原因分析：</strong> 创建该实例时，误选了默认的VPC和交换机。<br>
                    <strong>解决方案：</strong> 果断释放错误的实例，严格按照规划的网络配置重新创建，问题解决。
                </blockquote>

                <h4>3.2 阶段二：配置SSH免密登录</h4>
                <ul>
                    <li><strong>生成密钥对：</strong>在hadoop-master主节点上，为hadoop用户执行ssh-keygen命令，生成RSA公私钥对。</li>
                </ul>
                 <blockquote>
                    <strong>问题排查与解决：SSH的“死锁”</strong><br>
                    <strong>问题描述：</strong> 尝试使用ssh-copy-id命令分发公钥时，遭遇Permission denied (publickey)错误。<br>
                    <strong>原因分析：</strong> 阿里云服务器默认禁用了密码登录，而ssh-copy-id的工作原理是先通过密码登录一次来安装新公钥。<br>
                    <strong>解决方案：</strong> 采用手动方式完成公钥分发。在master节点上获取公钥内容，然后依次登录到所有节点，将公钥追加写入~/.ssh/authorized_keys文件，并严格设置目录和文件权限为700和600。
                </blockquote>
                <ul>
                    <li><strong>验证：</strong>在master节点上通过ssh hadoop-slave1等命令，验证到所有节点的免密登录均已成功。</li>
                </ul>

                <h4>3.3 阶段三：安装Java与Hadoop</h4>
                <ul>
                    <li><strong>安装Java：</strong>在所有三台服务器上，通过apt包管理器安装openjdk-8-jdk。</li>
                    <li><strong>下载Hadoop：</strong>在hadoop-master节点上，使用wget命令从清华大学开源镜像站下载Hadoop 3.3.6安装包。</li>
                    <li><strong>解压与链接：</strong>解压安装包，并创建一个名为hadoop的软链接指向解压后的目录，便于后续统一路径配置和升级。</li>
                </ul>

                <h4>3.4 阶段四：Hadoop核心配置</h4>
                <ul>
                    <li><strong>环境变量配置：</strong>在所有节点的~/.bashrc文件中添加JAVA_HOME和HADOOP_HOME等环境变量。</li>
                </ul>
                <blockquote>
                    <strong>问题排查与解决：环境变量的“作用域”</strong><br>
                    <strong>问题描述：</strong> 首次启动集群时，所有节点均报JAVA_HOME is not set错误。<br>
                    <strong>原因分析：</strong> Hadoop的启动脚本（非交互式Shell）不会加载.bashrc文件。<br>
                    <strong>解决方案：</strong> 在hadoop-env.sh文件中明确指定export JAVA_HOME，从根本上解决了问题。
                </blockquote>
                <ul>
                    <li><strong>XML文件配置：</strong>集中修改core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml等文件，定义文件系统、副本数、计算框架、资源管理器等关键参数。</li>
                    <li><strong>workers文件配置：</strong>编辑该文件，明确指定DataNode和NodeManager的节点。</li>
                </ul>

                <h4>3.5 阶段五：集群分发与启动</h4>
                <ul>
                    <li><strong>分发Hadoop：</strong>使用scp -r命令将配置好的整个Hadoop目录完整地复制到所有从节点。</li>
                    <li><strong>格式化HDFS：</strong>在master节点上，首次启动前执行hdfs namenode -format。</li>
                    <li><strong>启动与验证：</strong>执行start-all.sh启动集群，并通过jps命令在每个节点上验证核心进程的正常运行。</li>
                </ul>
            </section>

            <section>
                <h3>4. 实验结果与验证</h3>
                <h4>4.1 Web UI监控</h4>
                <p>通过配置阿里云安全组放行9870和8088端口，成功从本地浏览器访问了HDFS和YARN的管理界面，直观地监控了集群状态，确认所有节点均已激活。</p>
                <h4>4.2 运行MapReduce任务 (WordCount)</h4>
                <ol>
                    <li>在HDFS上创建/input目录，并上传XML配置文件作为输入数据。</li>
                    <li>执行hadoop jar ... wordcount /input /output命令提交计算任务。</li>
                    <li>任务执行成功，YARN界面显示了应用运行历史。</li>
                    <li>使用hdfs dfs -cat /output/part-r-00000命令，成功查看到了词频统计的输出结果。</li>
                </ol>
            </section>

            <section>
                <h3>5. 实验结论与心得</h3>
                <p>本次实验成功地在一个由三台阿里云ECS服务器组成的集群上，完整地部署并运行了Hadoop 3.3.6大数据平台。通过这个从零到一的实践过程，我深刻体会到：</p>
                <ul>
                    <li><strong>细节决定成败：</strong>分布式系统的搭建环环相扣，任何一个小的疏忽都可能导致整个集群无法正常工作。</li>
                    <li><strong>问题解决能力是核心：</strong>实验中遇到的每一个问题的解决过程，都是一次宝贵的学习经历，特别是解决SSH免密和JAVA_HOME问题的过程，让我对Linux系统和Hadoop脚本的运行机制有了更深的理解。</li>
                    <li><strong>理论与实践的结合：</strong>亲手搭建集群的过程，让Hadoop的理论架构变得鲜活和具体，不再是停留在书本上的抽象概念。</li>
                </ul>
                <p>总而言之，这次实验不仅让我掌握了Hadoop集群的搭建技能，更重要的是锻炼了严谨的工程实践态度和解决复杂问题的能力，为未来更深入地学习和应用大数据技术打下了坚实的基础。</p>
            </section>
        </div>
    </div>

    <script src="data.js"></script>
    <script>
        // ECharts initialization
        var myChart = echarts.init(document.getElementById('chart-container'));
        var option = {
            title: {
                text: '核心配置文件词频 Top 10',
                subtext: '数据来源: MapReduce on Hadoop Cluster',
                left: 'center',
                textStyle: {
                    color: '#333',
                    fontSize: 18
                }
            },
            tooltip: {
                trigger: 'item',
                formatter: '{a} <br/>{b} : {c} ({d}%)'
            },
            legend: {
                orient: 'vertical',
                left: 'left',
                top: 'middle',
                data: wordCountData.map(item => item.name)
            },
            series: [
                {
                    name: '词频',
                    type: 'pie',
                    radius: ['45%', '70%'],
                    center: ['50%', '55%'],
                    avoidLabelOverlap: false,
                    itemStyle: {
                        borderRadius: 10,
                        borderColor: '#fff',
                        borderWidth: 2
                    },
                    label: {
                        show: false,
                        position: 'center'
                    },
                    emphasis: {
                        label: {
                            show: true,
                            fontSize: '24',
                            fontWeight: 'bold'
                        }
                    },
                    labelLine: {
                        show: false
                    },
                    data: wordCountData
                }
            ]
        };
        myChart.setOption(option);

        // Scroll Animation
        document.addEventListener('DOMContentLoaded', () => {
            const cards = document.querySelectorAll('.card');
            
            const observer = new IntersectionObserver(entries => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('is-visible');
                        observer.unobserve(entry.target);
                    }
                });
            }, {
                threshold: 0.1
            });

            cards.forEach(card => {
                observer.observe(card);
            });
        });
    </script>
</body>
</html>
